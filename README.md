# Markov-chain-for-text-generation
Aim:- Our motivation behind this project is to make a probabilistic model that can predict the text based on previous state of outputs.

Data Prepration Part:-

  Training Data:-
    It's just a usual corpus of data.
  Test Data:-
    Data train on runtime only, so no test data.

Model Planning:-
  We'll use markov model, the best part about the markov model is that the future state depends only on current state, in witch there are   two states one is transmission probalility and other is emission probibility. Here we select the k end letters to predict the next         letter 
